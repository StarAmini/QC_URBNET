rm(list = ls())


raw_data <- readRDS("/home/samini/setareh/repos/QualityControl230524_Zurich/data/rawdata_zurich.RDS")
metadata <- raw_data$xyz

metadata_sensirion <- raw_data$xyz %>% filter(Sensor == "Sensirion")
sensor_ids_sensirion <- metadata_sensirion$ID
qc_05_data_sensirion <- qc_05_data[, colnames(qc_05_data) %in% sensor_ids_sensirion]

# Load necessary libraries
library(geosphere)
library(dplyr)  # install.packages("dplyr")
library(xts)  # install.packages("xts")

# ---------------------------
# Load the RDS file
# ---------------------------

# raw_data$data is your time-series data (a list of xts objects or a single xts object)
# raw_data$xyz is your metadata data frame.

# ---------------------------
# Define functions for spatial outlier detection
# ---------------------------

# Function to compute the pairwise distance matrix.
# Distances are in meters.
# -------------------------------
# Normalize metadata column names
# -------------------------------
guess_col <- function(df, candidates) {
  cn <- names(df)
  for (cand in candidates) {
    hit <- grep(paste0("^", cand, "$|\\b", cand, "\\b"), cn, ignore.case = TRUE, value = TRUE)
    if (length(hit)) return(hit[1])
  }
  NA_character_
}

id_col      <- if ("ID" %in% names(metadata)) "ID" else guess_col(metadata, c("id","sensor_id","station","station_id"))
lat_col     <- if ("LAT" %in% names(metadata)) "LAT" else guess_col(metadata, c("lat","latitude","y"))
lon_col     <- if ("LON" %in% names(metadata)) "LON" else guess_col(metadata, c("lon","long","longitude","x","lng"))
landuse_col <- if ("Landuse" %in% names(metadata)) "Landuse" else guess_col(metadata, c("landuse","land_use","land use","lulc","class","surface"))

rename_if <- function(df, from, to) {
  if (!is.na(from) && from != to && from %in% names(df)) dplyr::rename(df, !!to := dplyr::all_of(from)) else df
}

metadata <- metadata |>
  rename_if(id_col, "ID") |>
  rename_if(lat_col, "LAT") |>
  rename_if(lon_col, "LON") |>
  rename_if(landuse_col, "Landuse")

req <- c("ID","LAT","LON","Landuse")
missing_req <- setdiff(req, names(metadata))
if (length(missing_req)) stop("Metadata is missing columns: ", paste(missing_req, collapse = ", "))

# Intersect station sets
ts_cols <- colnames(if (inherits(qc_ts,"xts")) as.data.frame(qc_ts) else qc_ts)
common_ids <- intersect(ts_cols, metadata$ID)
if (!length(common_ids)) stop("No overlapping station IDs between qc_05_data and metadata.")

# -------------------------------
# Helpers
# -------------------------------
compute_distance_matrix <- function(metadata, id_col = "ID", lat_col = "LAT", lon_col = "LON") {
  sensor_ids <- metadata[[id_col]]
  n <- length(sensor_ids)
  dist_matrix <- matrix(0, nrow = n, ncol = n)
  for (i in 1:n) {
    lat1 <- metadata[i, lat_col]; lon1 <- metadata[i, lon_col]
    for (j in 1:n) {
      lat2 <- metadata[j, lat_col]; lon2 <- metadata[j, lon_col]
      dist_matrix[i, j] <- geosphere::distHaversine(c(lon1, lat1), c(lon2, lat2))
    }
  }
  rownames(dist_matrix) <- sensor_ids
  colnames(dist_matrix) <- sensor_ids
  as.data.frame(dist_matrix)
}

# -------------------------------
# Spatial QC core (no plots)
# -------------------------------
spatial_outlier_detection <- function(timeseries_df, metadata,
                                      threshold_multiplier = 6,  # k
                                      abs_floor = 3,             # δ (°C)
                                      id_col = "ID",
                                      min_neighbors_req = 2,
                                      neff_star = 1.5,
                                      k_neighbors_cap = 5,
                                      radius_cap_m = 3000,
                                      weight_decay = NULL,
                                      landuse_mode = c("strict","graded"),
                                      return_diagnostics = TRUE) {
  landuse_mode <- match.arg(landuse_mode)
  
  # Distance + base weights
  D <- compute_distance_matrix(metadata, id_col)
  diag(D) <- NA
  if (is.null(weight_decay)) {
    weight_decay <- stats::median(as.matrix(D), na.rm = TRUE)
  }
  W0 <- exp(-(as.matrix(D)^2) / (2 * weight_decay^2))
  W0[is.na(W0)] <- 0
  
  # Align stations
  sensor_ids <- intersect(colnames(timeseries_df), metadata[[id_col]])
  lu <- as.character(metadata$Landuse[match(sensor_ids, metadata[[id_col]])])
  ok <- !is.na(lu) & nzchar(lu)
  sensor_ids <- sensor_ids[ok]; lu <- lu[ok]
  
  D  <- as.matrix(D)[sensor_ids, sensor_ids, drop = FALSE]
  W0 <- W0[sensor_ids, sensor_ids, drop = FALSE]
  
  # Land-use similarity
  if (landuse_mode == "strict") {
    LU <- outer(lu, lu, FUN = Vectorize(function(a,b) as.numeric(a == b)))
  } else {
    LU <- outer(lu, lu, FUN = Vectorize(function(a,b){
      if (a == b) return(1)
      if ((a %in% c("Vegetated Areas","Forests")) && (b %in% c("Vegetated Areas","Forests"))) return(0.4)
      if ((a == "Water") || (b == "Water")) return(0.0)
      if ((a %in% c("Sealed Areas") && b %in% c("Vegetated Areas","Forests")) ||
          (b %in% c("Sealed Areas") && a %in% c("Vegetated Areas","Forests"))) return(0.0)
      0.0
    }))
  }
  dimnames(LU) <- list(sensor_ids, sensor_ids)
  
  # Combine and hard-cap by radius
  W <- W0 * LU
  for (sid in rownames(W)) {
    d <- D[sid, ]
    cand <- names(d)[!is.na(d) & d <= radius_cap_m]
    if (length(cand) == 0) {
      W[sid, ] <- 0
    } else {
      ord <- order(d[cand])           # nearest first
      keep <- cand[ord][seq_len(min(k_neighbors_cap, length(ord)))]
      W[sid, !(colnames(W) %in% keep)] <- 0
    }
  }
  # Safety: zero weights beyond cap
  W[as.matrix(D) > radius_cap_m] <- 0
  
  # Timeseries to matrix
  if (is.list(timeseries_df) && !inherits(timeseries_df, "xts")) {
    timeseries_df <- do.call(cbind, timeseries_df)
  }
  if (inherits(timeseries_df, "xts")) {
    ts_df <- as.data.frame(timeseries_df); time_index <- zoo::index(timeseries_df)
    rownames(ts_df) <- as.character(time_index)
  } else {
    ts_df <- timeseries_df
    time_index <- rownames(ts_df)
    if (is.null(time_index)) time_index <- seq_len(nrow(ts_df))
  }
  ts_df <- ts_df[, sensor_ids, drop = FALSE]
  
  X <- as.matrix(ts_df)
  n_time   <- nrow(X)
  n_sensor <- ncol(X)
  
  cleaned <- ts_df
  flagged <- ts_df; flagged[,] <- 0L
  
  # Optional diagnostics containers
  if (isTRUE(return_diagnostics)) {
    avg_mat <- matrix(NA_real_, n_time, n_sensor, dimnames = list(NULL, sensor_ids))
    sd_mat  <- matrix(NA_real_, n_time, n_sensor, dimnames = list(NULL, sensor_ids))
    eff_mat <- matrix(NA_real_, n_time, n_sensor, dimnames = list(NULL, sensor_ids))
  }
  
  W2 <- W * W
  abs_floor_vec <- rep(abs_floor, n_sensor)
  
  for (t in seq_len(n_time)) {
    x <- X[t, ]
    valid_mask <- as.integer(!is.na(x))
    x_filled <- ifelse(is.na(x), 0, x)
    
    # Weighted mean
    wsum <- as.vector(W %*% valid_mask)
    xsum <- as.vector(W %*% (valid_mask * x_filled))
    mu   <- xsum / wsum
    mu[wsum == 0] <- NA_real_
    
    # Weighted variance against mu_i (matrix-safe)
    Xmat <- matrix(rep(x_filled, each = n_sensor), nrow = n_sensor)
    Mmat <- matrix(mu, nrow = n_sensor, ncol = n_sensor)
    diff <- Xmat - Mmat
    valid_mat <- matrix(valid_mask, nrow = n_sensor, ncol = n_sensor, byrow = TRUE)
    
    num  <- rowSums((W * valid_mat) * (diff^2), na.rm = TRUE)
    den  <- pmax(wsum, 1e-12)
    sig2 <- num / den
    sig2[wsum == 0] <- NA_real_
    sig  <- sqrt(sig2)
    
    # Neighbor counts and effective support
    n_neigh <- rowSums((W > 0) * valid_mat)
    num_eff <- (rowSums(W * valid_mat))^2
    den_eff <- rowSums((W2) * valid_mat)
    neff    <- num_eff / pmax(den_eff, 1e-12)
    
    # Thresholds
    thr_k <- threshold_multiplier * sig
    
    # Base rule
    outlier <- (threshold_multiplier * sig > 0.5) &              # your min_threshold
      (abs(x - mu) > thr_k) &
      (abs(x - mu) > abs_floor_vec) &
      (!is.na(x))
    
    # Support requirement: at least 2 neighbors OR Neff >= 1.5
    support_ok <- (n_neigh >= min_neighbors_req) | (neff >= neff_star)
    outlier <- outlier & support_ok & (wsum > 0)
    
    cleaned[t, ] <- ifelse(outlier, NA, x)
    flagged[t, ] <- as.integer(outlier)
    
    if (isTRUE(return_diagnostics)) {
      avg_mat[t, ] <- mu
      sd_mat[t, ]  <- sig
      eff_mat[t, ] <- neff
    }
  }
  
  # Return xts if input was xts
  if (inherits(timeseries_df, "xts")) {
    cleaned <- xts::xts(as.matrix(cleaned), order.by = as.POSIXct(time_index))
    flagged <- xts::xts(as.matrix(flagged), order.by = as.POSIXct(time_index))
  }
  
  out <- list(cleaned_df = cleaned, flagged_df = flagged)
  
  if (isTRUE(return_diagnostics)) {
    # Build a compact diagnostics long table (no plots)
    time_col <- if (inherits(timeseries_df,"xts")) as.POSIXct(time_index) else time_index
    long <- data.frame(
      time    = rep(time_col, each = n_sensor),
      station = rep(colnames(X),  times = n_time),
      avg     = as.vector(avg_mat),
      sigma   = as.vector(sd_mat),
      Neff    = as.vector(eff_mat),
      flagged = as.vector(as.matrix(flagged)),
      stringsAsFactors = FALSE
    )
    out$diagnostics <- list(long = long, sensor_ids = sensor_ids)
  }
  
  out
}

# -------------------------------
# Run per-month, stitch, save
# -------------------------------
# Build month keys from qc_ts
idx <- if (inherits(qc_ts,"xts")) zoo::index(qc_ts) else rownames(qc_ts)
if (is.null(idx)) stop("qc_ts has no time index or rownames.")
idx <- as.POSIXct(idx, tz = "UTC")
month_keys <- unique(format(idx, "%Y-%m"))

