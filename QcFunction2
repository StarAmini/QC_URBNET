##QC_URBNET_src_QcFunction2

tm_gross_error <- function(xts_vector) {
  
  # Identify dates with outliers (values > 60 or < -40)
  rm_dates <- time(xts_vector[xts_vector > 60 | xts_vector < -40 | xts_vector == -40 | xts_vector == 60])
  
  # Create a copy of the input data for cleaning and flagging
  qc_data <- qc_data_flagged <- xts_vector
  
  # Set outlier values to NA in qc_data
  qc_data[rm_dates] <- NA
  
  # Flag outliers in qc_data_flagged
  qc_data_flagged[!is.na(qc_data_flagged)] <- 0  # Default flag to 0
  qc_data_flagged[rm_dates] <- 1  # Flag outliers as 1
  
  # Create the output list
  out <- list(
    qc_data = qc_data,
    qc_data_flagged = qc_data_flagged
  )
  
  return(out)
}

#######################################################################
season_thresholds <- list(
  winter = list(min_val = -24.44, max_val = 23.54),
  spring = list(min_val = -21.05, max_val = 38.08),
  summer = list(min_val = 7.85, max_val = 46.26),
  autumn = list(min_val = -8.42, max_val = 40.87)
)


# Helper function to determine the season of a given date
get_season <- function(date) {
  month <- as.numeric(format(date, "%m"))
  if (month %in% c(12, 1, 2)) {
    return("winter")
  } else if (month %in% 3:5) {
    return("spring")
  } else if (month %in% 6:8) {
    return("summer")
  } else {
    return("autumn")
  }
}

# Updated function to handle seasonal thresholds
tm_range_outliers_seasonal <- function(xts_vector, season_thresholds) {
  # Get dates and initialize outputs
  dates <- index(xts_vector)
  seasons <- sapply(dates, get_season)  # Determine season for each date
  
  qc_data <- xts_vector  # Initialize cleaned data
  qc_data_flagged <- xts_vector  # Initialize flagged data
  
  qc_data_flagged[] <- 0  # Default: no flags
  
  for (season in names(season_thresholds)) {
    # Retrieve seasonal thresholds
    thresholds <- season_thresholds[[season]]
    season_mask <- seasons == season  # Identify dates in the current season
    
    # Identify indices outside threshold range for this season
    outlier_indices <- which(xts_vector < thresholds$min_val | 
                               xts_vector > thresholds$max_val)
    
    # Apply the season mask
    rm_dates<- outlier_indices[season_mask[outlier_indices]]
    
    # Set flagged and cleaned data for the outliers
    qc_data[rm_dates] <- NA
    qc_data_flagged[rm_dates] <- 1
  }
  
  # Output the results as a list
  out <- list(
    qc_data = qc_data,
    qc_data_flagged = qc_data_flagged
  )
  
  return(out)
}

###########################################################################################

tm_temporal_outliers <- function(xts_vector,
                                 min_diff = -5,
                                 max_diff = 6){
  
  diffs1 <- c(xts_vector - stats::lag(xts_vector, k = -1))
  diffs2 <- c(stats::lag(xts_vector, k = 1) - xts_vector)
  
  rm_dates1 <- which(diffs1 < min_diff | diffs1 > max_diff)
  rm_dates2 <- which(diffs2 < min_diff | diffs2 > max_diff)
  
  rm_dates <- intersect(rm_dates1, rm_dates2)
  #union
  #intersect
  rm_dates <- time(xts_vector[rm_dates])
  
  qc_data <- qc_data_flagged <- xts_vector
  qc_data[rm_dates] <- NA
  qc_data_flagged[!is.na(qc_data_flagged)] <- 0
  qc_data_flagged[rm_dates] <- 1
  
  out <- list(
    qc_data = qc_data,
    qc_data_flagged = qc_data_flagged
  )
  
  return(out)
  
}

######################################################################################

tm_persistence_outliers1 <- function(xts_vector, min_change = 0.04, n_window = 0.5, by = "10 min", length_out = 18) {
  # Calculate absolute differences
  diffs <- abs(diff(xts_vector))
  
  # Custom sum function to handle NA tolerance
  custom_sum <- function(xts_vector_chunk, n_window = 0.5) {
    n_nas <- sum(is.na(xts_vector_chunk))  # Count the number of NAs
    if (n_nas > n_window * length(xts_vector_chunk)) {
      return(NA)  # Too many NAs, return NA
    } else {
      return(sum(xts_vector_chunk, na.rm = TRUE))  # Sum non-NA values
    }
  }
  
  # Apply rolling window sum
  rolling_sum <- zoo::rollapply(diffs, width = 18, FUN = function(chunk) custom_sum(chunk, n_window = n_window), fill = NA, align = "right")
  
  # Flag bins where total change < min_change
  flagged_periods <- rolling_sum < min_change
  flagged_timestamps <- which(flagged_periods)
  
  # Generate flagged date ranges
  flagged_dates <- lapply(flagged_timestamps, function(ts) {
    seq(from = index(xts_vector)[ts], by = by, length.out = length_out)
  })
  
  # Concatenate flagged dates into a single vector
  if (length(flagged_dates) == 0) {
    rm_dates <- NULL
  } else {
    rm_dates <- unique(do.call("c", flagged_dates))
  }
  
  # Ensure flagged dates are within the series index
  rm_dates <- rm_dates[rm_dates %in% index(xts_vector)]
  
  # Build the output
  qc_data <- xts_vector
  qc_data[rm_dates] <- NA
  
  # Create binary flag series
  qc_data_flagged <- xts(rep(0, length(index(xts_vector))), order.by = index(xts_vector))
  qc_data_flagged[rm_dates] <- 1
  
  return(list(qc_data = qc_data, qc_data_flagged = qc_data_flagged))
}


tm_persistence_outliers2 <- function(xts_vector, n_window = 0.5, by = "10 min", length_out = 18) {
  # Custom function to calculate standard deviation with NA tolerance
  custom_sd <- function(chunk, n_window = 0.5) {
    n_nas <- sum(is.na(chunk))  # Count number of NAs
    if (n_nas > n_window * length(chunk)) {
      return(NA)  # Too many NAs, return NA
    } else {
      return(sd(chunk, na.rm = TRUE))  # Calculate standard deviation, ignoring NAs
    }
  }
  
  # Apply rolling window of 3 hours (18 intervals for 10-minute data)
  rolling_sd <- zoo::rollapply(
    xts_vector,
    width = 18,  # 18 intervals for 10-minute frequency (equivalent to 3 hours)
    FUN = function(chunk) custom_sd(chunk, n_window = n_window),
    fill = NA,
    align = "right"
  )
  
  # Flag windows with standard deviation == 0
  flagged_periods <- rolling_sd == 0
  flagged_timestamps <- which(flagged_periods)
  
  # Generate flagged date ranges (covering the window of length `length_out`)
  flagged_dates <- lapply(flagged_timestamps, function(ts) {
    seq(from = index(xts_vector)[ts], by = by, length.out = length_out)
  })
  
  # Concatenate flagged dates into a single vector
  if (length(flagged_dates) == 0) {
    rm_dates <- NULL
  } else {
    rm_dates <- unique(do.call("c", flagged_dates))
  }
  
  # Ensure flagged dates are within the index of the original series
  rm_dates <- rm_dates[rm_dates %in% index(xts_vector)]
  
  # Create cleaned data by setting flagged dates to NA
  qc_data <- xts_vector
  qc_data[rm_dates] <- NA
  
  # Create a binary flag series (1 for flagged, 0 for not flagged)
  qc_data_flagged <- xts(rep(0, length(index(xts_vector))), order.by = index(xts_vector))
  qc_data_flagged[rm_dates] <- 1
  
  return(list(qc_data = qc_data, qc_data_flagged = qc_data_flagged))
}


###########################################################################################################33

tm_extreme_quantiles_outliers <- function(xts_vector,
                                          ext_lim_factor = 4){
  
  tavg_filter_l <- sapply(1:12, function(x) {
    xts_obj_sample <- xts_vector[, 1][as.numeric(format(time(xts_vector), "%m")) == x]
    quantile(xts_obj_sample, .25, na.rm = TRUE) - ext_lim_factor * IQR(xts_obj_sample, na.rm = TRUE)
  })
  
  tavg_filter_h <- sapply(1:12, function(x) {
    xts_obj_sample <- xts_vector[, 1][as.numeric(format(time(xts_vector), "%m")) == x]
    quantile(xts_obj_sample, .75, na.rm = TRUE) + ext_lim_factor * IQR(xts_obj_sample, na.rm = TRUE)
  })
  
  rm_dates <- do.call(c, sapply(1:12, function(x) {
    xts_obj_sample <- xts_vector[, 1][as.numeric(format(time(xts_vector), "%m")) == x]
    zoo::index(
      xts_obj_sample[xts_obj_sample <= tavg_filter_l[x] |
                       xts_obj_sample >= tavg_filter_h[x]]
    )
  }))
  
  qc_data <- qc_data_flagged <- xts_vector
  qc_data[rm_dates] <- NA
  qc_data_flagged[!is.na(qc_data_flagged)] <- 0
  qc_data_flagged[rm_dates] <- 1
  
  out <- list(
    qc_data = qc_data,
    qc_data_flagged = qc_data_flagged
  )
  
  return(out)
  
}

#####################################################################################################

get_spatial_nearby_points <- function(xy_target,
                                      xyz_metadata,
                                      lmt_xy,
                                      lmt_n)
{
  
  pos_target <- match(xy_target, xyz_metadata$ID)
  
  target <- xyz_metadata[pos_target, c("LON", "LAT")]
  nearby <- xyz_metadata[, c("LON", "LAT")]
  
  out <- xyz_metadata[, c("ID", "LON", "LAT")]
  out$distance <- geosphere::distHaversine(target, nearby)
  out <- out[out$distance < lmt_xy, ]
  out <- out[order(out$distance), ]
  out <- out[1:(lmt_n + 1), ]
  out <- out[complete.cases(out), ]
  out <- as.character(out$ID)
  
  return(out)
  
}


spatemp_value_check_NOLU2 <- function(xy_target,
                                      xy_database,
                                      xts_database,
                                      params = list(
                                        lmt_xy_ = 2500,
                                        lmt_n_ = 5,
                                        n_nearby_ = 5)
) {
  
  # spatial check
  
  xy_nearby <- get_spatial_nearby_points(xy_target = xy_target,
                                         xyz_metadata = xy_database,
                                         lmt_xy = params$lmt_xy_,
                                         lmt_n = params$lmt_n_)
  xy_nearby <- xy_nearby[-1]
  
  target_xts <- xts_database[, xy_target]
  nearby_xts <- xts_database[, xy_nearby]
  
  dif_target_nearby <- lapply(
    seq_len(ncol(nearby_xts)),
    function(idd) {
      
      dif_ts <- target_xts - nearby_xts[, idd]
      
      dif_098 <- quantile(dif_ts, 0.9888, na.rm = TRUE)
      flag_098_pos <- time(dif_ts[dif_ts >= dif_098])
      
      dif_1_098 <- quantile(dif_ts, 1 - 0.9888, na.rm = TRUE)
      flag_098_neg <- time(dif_ts[dif_ts <= dif_1_098])
      
      out_ts <- dif_ts
      out_ts[!is.na(out_ts)] <- 0
      out_ts[c(flag_098_pos, flag_098_neg)] <- 1
      
      out_ts
    }
  )
  
  dif_target_nearby <- do.call(cbind, dif_target_nearby)
  dif_target_nearby <- rowSums(dif_target_nearby, na.rm = TRUE)
  # time step in which at least 5 nearby points are flagged
  dif_target_nearby <- which(dif_target_nearby >= params$n_nearby_)
  # getting the dates
  dif_target_nearby <- time(target_xts)[dif_target_nearby]
  dif_target_nearby <- as.character(dif_target_nearby)
  
  # temporal check
  # previous date
  dif_target_target_pre <-  target_xts - stats::lag(target_xts, k = -1)
  quant_098_pre <- quantile(
    dif_target_target_pre,
    0.9888,
    na.rm = TRUE
  )
  dif_target_target_pre <- dif_target_target_pre[
    dif_target_target_pre > quant_098_pre |
      dif_target_target_pre < -quant_098_pre
  ]
  dif_target_target_pre <- as.character(time(dif_target_target_pre))
  
  # next date
  dif_target_target_nex <-  stats::lag(target_xts, k = 1) - target_xts
  quant_098_next <- quantile(
    dif_target_target_nex[dif_target_target_nex > 0],
    0.9888,
    na.rm = TRUE
  )
  dif_target_target_nex <- dif_target_target_nex[
    dif_target_target_nex > quant_098_next |
      dif_target_target_nex < -quant_098_next
  ]
  dif_target_target_nex <- as.character(time(dif_target_target_nex))
  dif_target_target <- intersect(dif_target_target_pre, dif_target_target_nex)
  
  # intersecting both checks
  rm_dates <- intersect(dif_target_target, dif_target_nearby)
  
  
  print("rm_dates:")
  print(rm_dates)
  print(paste("Number of dates in rm_dates: ", length(rm_dates)))
  
  qc_data <- qc_data_flagged <- target_xts
  qc_data[rm_dates] <- NA
  qc_data_flagged[!is.na(qc_data_flagged)] <- 0
  qc_data_flagged[rm_dates] <- 1
  
  out <- list(
    qc_data = qc_data,
    qc_data_flagged = qc_data_flagged,
    rm_dates = rm_dates # Add rm_dates here
  )
  
  return(out)
}
##########################################################################

spatial_outlier_detection <- function(xy_database, xts_database, params = list(
  threshold_multiplier = 3.0,
  weight_decay = NULL
)) {
compute_distance_matrix <- function() {
  sensor_ids <- xy_database$ID
  n <- length(sensor_ids)
  dist_matrix <- matrix(0, nrow = n, ncol = n, dimnames = list(sensor_ids, sensor_ids))
  
  for (i in seq_len(n)) {
    lat1 <- xy_database$LAT[i]
    lon1 <- xy_database$LON[i]
    for (j in seq_len(n)) {
      lat2 <- xy_database$LAT[j]
      lon2 <- xy_database$LON[j]
      dist_matrix[i, j] <- distHaversine(c(lon1, lat1), c(lon2, lat2))
    }
  }
  
  return(as.data.frame(dist_matrix))
}

spatial_outlier_detection <- function(params = list(
  threshold_multiplier = 3.0,
  weight_decay = NULL
)) {
  
  dist_matrix <- compute_distance_matrix()
  diag(dist_matrix) <- NA
  
  if (is.null(params$weight_decay)) {
    params$weight_decay <- median(as.numeric(dist_matrix), na.rm = TRUE)
  }
  
  weight_matrix <- exp(- (as.matrix(dist_matrix)^2) / (2 * params$weight_decay^2))
  weight_matrix[is.na(weight_matrix)] <- 0
  
  sensor_ids <- intersect(colnames(xts_database), xy_database$ID)
  ts_data <- xts_database[, sensor_ids]
  qc_data <- ts_data
  qc_data_flagged <- ts_data
  qc_data_flagged[] <- 0
  
  ts_arr <- as.matrix(ts_data)
  time_index <- index(xts_database)
  n_time <- nrow(ts_arr)
  n_sensor <- ncol(ts_arr)
  
  for (t in seq_len(n_time)) {
    x <- ts_arr[t, ]
    valid_mask <- !is.na(x)
    x_filled <- ifelse(is.na(x), 0, x)
    
    weight_sum <- rowSums(weight_matrix * valid_mask, na.rm = TRUE)
    weighted_sum <- weight_matrix %*% x_filled
    weighted_avg <- weighted_sum / weight_sum
    
    diff <- sweep(weight_matrix * valid_mask, 2, weighted_avg, "-")
    weighted_var <- rowSums((diff^2) * valid_mask, na.rm = TRUE) / weight_sum
    weighted_std <- sqrt(weighted_var)
    
    outlier_mask <- abs(x - weighted_avg) > params$threshold_multiplier * weighted_std & !is.na(x)
    
    qc_data[t, ] <- ifelse(outlier_mask, NA, x)
    qc_data_flagged[t, ] <- as.integer(outlier_mask)
  }
  
  return(list(qc_data = qc_data, qc_data_flagged = qc_data_flagged))
}
}




